\label{chap3}

\section{Portuguese-English Parallel Corpus}

For the purpose of this work, I've created a Portuguese-English parallel corpus of research articles related to radiology. For each research article there is:

\begin{enumerate}
\item Original Portuguese text
\item Human Translated English text
\item Machine Translated English text (Yandex) 
\item Machine Translated English text (Google) 
\item Machine Translation + Post-Editing English text (Google + Unbabel) 
\end{enumerate}

\noindent In the next few lines I will explain how I've constructed the corpus. 

\subsection{Web Crawl of the articles (1,2)}

First, I needed a list of articles related to radiography that were available both in English and in Portuguese. To get this list I’ve used the  NCBO Entrez Programming Utilities (E-utilities)\footnote{https://www.ncbi.nlm.nih.gov/books/NBK25501/} to query the PubMed database with the search query “portuguese[Language] AND english[Language] AND radiography[MeSH Major Topic] AND hasabstract[text]” (search done on 11/12/2016). The last filter is used to avoid getting texts for which only the title is available. 

Then I programmatically crawled each article PubMed page to get the URL where the full article could be found. Most of the articles were hosted in SciELO\footnote{http://www.scielo.br/} so for the sake of consistency I've only included in the corpus articles hosted in there. 

For the purposes of this work, it made sense to only include articles for which the original language is Portuguese, so I've also filtered the corpus by this parameter. 

Finally, I've programmatically crawled the articles SciELO pages to get both language versions of articles text. I've extracted from the HTML everything from the abstract until, but not including, the references/bibliography.

Three of the article contained were about surveys, containing to much vocabulary about radiology. They were excluded from the corpus.

What is left is a parallel corpus of 53 articles, distributed by journal in the following way:

\begin{table}[ht]
\centering
\caption{Number of articles by journal in parallel corpus}
\label{table:articles_by_journal}
\begin{tabular}{@{}ll@{}}
\toprule
\multicolumn{1}{c}{\textbf{Journal}}                 & \textbf{Number Of Articles} \\ \midrule
Arquivos Brasileiros de Cardiologia         & 26                          \\
Jornal Brasileiro de Pneumologia            & 14                          \\
Revista do Colégio Brasileiro de Cirurgiões & 4                           \\
Brazilian Journal of Otorhinolaryngology    & 2                           \\
Arquivos Brasileiros de Cirurgia Digestiva  & 2                           \\
Revista Brasileira de Cirurgia Cardiovascular        & 2                           \\
Jornal da Sociedade Brasileira de Fonoaudiologia     & 1                           \\
Einstein (São Paulo)                                 & 1                           \\
Revista Brasileira de Reumatologia                   & 1                           \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Note On Human Translations}

It is not known for sure how exactly the original human translations were done, since some of the articles are not recent and some of the journals did not answer my emails questioning about this, but all the answers received mentioned the use of specialized translation services. Having said this, we assume that the translations are of high quality since they were published by scientific magazines. 

\subsection{Yandex Translation (3)}

The Portuguese version of the articles were machine translated using Yandex's free Translate API\footnote{https://tech.yandex.com/translate/}. Each translation request had a limit of 10000 characters so an algorithm was used to break the text to various pieces, without breaking the text in the middle of sentences, send the translation request for each piece and then join everything back.

\subsection{Google and Unbabel Translation (4,5)}

Both MT with Google and MT+PE with Unbabel were obtained using Unbabel's API\footnote{http://developers.unbabel.com/}. The requests for Unbabel Translations have a limit of words, so an algorithm similar used for the Yandex Translations was used. 

\section{Annotation}

All the English versions of the articles in the corpus were annotated thrice with RadLex terms, one time using a direct matching approach and two using two of the built-in matching strategies provided by NOBLE Coder. I'm calling the three approaches Direct Match\footnote{See \ref{Named-entity Recognition}}, All Match and Best Match\footnote{See \ref{NOBLE Coder}}.

Each class of the RadLex ontology has a \textit{preferred name} and a list of synonyms. For all the cases the output of each annotation consists in the set of the preferred names of the terms of RadLex that are mentioned in the corresponding article. I normalize all the mentions to the preferred name so that a use of the preferred name in one translation and the use of one of the synonyms in another translation are considered mentions of the same term. 

\subsection{Direct Match - Annotation with NCBO Annotator}

The articles were annotated with the NCBO Annotator using the REST API\footnote{\url{http://data.bioontology.org/documentation\#nav_annotator}}. The default parameters were used, namely:

\begin{itemize}
\setlength{\itemsep}{1pt}
\setlength{\parskip}{0pt}
\setlength{\parsep}{0pt}
\item \textbf{expand\_class\_hierarchy} - false
\item \textbf{expand\_mappings}        - false
\item \textbf{minimum\_match\_length}   - 3
\item \textbf{exclude\_numbers}        - false
\item \textbf{whole\_word\_only}        - true
\item \textbf{exclude\_synonyms}       - false
\item \textbf{longest\_only}			  - false
\end{itemize} 

\subsection{All Match and Best Match - Annotation with NOBLE Coder}

NOBLE Coder was chosen against others similar tools because of it's comparable quality and higher ease of use. Each of the articles was annotated twice with this tool, using two different matching strategies, Best match and All match.

The commands used to annotate the reports were these:


\begin{lstlisting}[language=bash]
$ java -jar NobleCoder-1.0.jar -terminology radlex \
-input [portuguese reports path] -output [output path] \
-search all-match\textit{

$ java -jar NobleCoder-1.0.jar -terminology radlex \
-input [portuguese reports path] -output [output path] \
-search best-match
\end{lstlisting}


The RadLex ontology .owl file had to be edited before it could be correctly processed and uploaded to NOBLE Coder. In the original .owl file the properties  "Preferred\_name" and "Synonym" are considered to be \textit{DatatypeProperty} but I had to change both to \textit{AnnotationProperty}. That is, where in the file was


\begin{lstlisting}[language=xml]
<owl:DatatypeProperty rdf:ID="Preferred_name">
</owl:DatatypeProperty>
\end{lstlisting}


I've had to change it to:


\begin{lstlisting}[language=xml]
<owl:AnnotationProperty rdf:ID="Preferred_name">
</owl:AnnotationProperty>
\end{lstlisting}


And the analogous thing for the "Synonym" property.

\section{Evaluation}

The annotations of each MT or MT+PE translated article were compared against the annotations of corresponding HT translated article, which was considered a gold standard. Both Micro- and Macro- Precision, Recall and F1-scores were calculated. This was done for each matching approach. 

These methods measure how similar are the terms annotated on the MT or MT+PE texts to the terms annotated on the HT texts. They don't say nothing about the quality of the annotations, however is that measured. 





 